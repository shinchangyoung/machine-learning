```
4월 26일 머신러닝
강의 목표 :  numpy, pandas를 이해하고 데이터 조작 및 변환을 수행 할 수 있다, 
		 데이터 분석 시 필요한 그룹화 집계를 수행할 수 있다

데이터 분석 주요 패키지
numpy : 수치 해석 라이브러리 -> 행렬, 벡터, 연산
	   
pandas : 1차원 시리즈, 2차원 데이터프레임 -> 조작, 필터링, 그룹화, 연산, 등에서 사용
		
matplotlib : 데이터 시각화 패키지 -> figure 그래프나 그림을 그리는 공간이라고 이해한다 : 데이터를 연산한 결과를 시각화 하기 위해서는 시각화 시킬 matplotlib패키지를 사용해야하는데 이는 figure라는 공간에서 그래프
															    혹은 그림을 표현할 떄 사용한다

dataseries: 데이터 시리즈는 [10, 20, 30]와 같은 한줄로 정리가 된 데이터들의 목록인데 이렇게 숫작가 한줄로 정리 되어있는것처럼 1차원적이고 예시로는 엑셀의 한 열로 생각하자
dataframe : 데이터 프레임은 데이터들의 표인데 이는 시리즈 한 열이 여러개가 모이는 형태를 데이터 프레임이라고 하며 이는 행과 열로 구분이 가능한 2차적이고 엑셀로 따지면 한 엑셀의 표라고 생각하면된다 

데이터 조작
pandas를 사용하해서 데이터를 쉽게 다룰 수 있도록 데이터 프레임을 생성해준다
apply() : 데이터프레임의 각 열이나 행에 함수를 적용할떄 사용 -> 데이터프레임에서 사용되는 
map() : 특정 열의 값들을 매핑해주는 함수
value_counts() 특정 열의 고유한 값들의 빈도수를 확인
cut(): 연속형 데이터를 구간별로 나눌 때 사용
astype: 특정 열의 데이터 타입을 변경


코랩 사용방법
처음에 코랩을 사용하면 우측메뉴에서 확인되는 +있는데 그걸 클릭하면 폴더를 만들어서 폴더 생성가능
파일명은 파일명을 클릭하면 바로 수정이 가능하다
1강의.ipynb
ipynb : 파이썬코드를 서용하기 위한 확장자이다
확장자는 파일 뒤에 붙이는 프로그램의 종류이다 ipynb는 파이썬이라는 종류의 확장자라는 뜻
섹션은 어른쪽에 있는 좀선 세개를 클하면 목차가 나오게 되는데 섹션이 나온다 
코랩에서 새파일을 열게 되면 기본적으로 생성이 되어있는 코드셀(코드입력부분)이  생성되어있는데 코드셀의 위 부분에 커서를 올리면 +코드, +텍스트가 셀을 추가할 수 있다
**섹션 목차를 만들기**
+텍스트를 클릭후 텍스트셀이 생성이 되는데 #를 누르면 목차에 추가되는 텍스트 셀이 생성이 된다
ctrl+enter로 코드 실행이 가능

그룹화의 집계

pandas를 사용해서 데이터를 쉽게 다룰 수 있도록 데이터프레임 생성 
groupby():  데이터를 특정 열 기준으로 그룹화
agg() : 그룹에 대해 집계 함수를 적용가능
privot_table() : 데이터를 인덱스와 값으로 재구성 할 수 있음
```

```py
#1. 데이터 조작
import pandas as pd

data = {'one':[1,2,3,4,5,6,7], 'two' :[10,20,30,40,50,60,70], 'three' :[100,200,300,400,500,600,700]}
df = pd.DataFrame(data)

# apply() : 각 열의 값에 함수를 적용하고 새롱게 열을 생성 
#lambda 매개변수들: 표현식
df['one_plus'] = df['one'].apply(lambda x : x + 3)
df['two_plus'] = df['two'].apply(lambda x : x - 1)
df

#map() : 매핑
#매핑이라는건 어떤 값을 다른 값으로 대응해준다
mapping = {10 : 'low', 20 : 'low', 30: 'low', 40: 'meium', 50: 'medium', 60: 'high', 70: 'high'}
mapping2 = {10 : 'low', 20 : 'low', 30: 'low', 40: 'meium', 50: 'medium', 60: 'high'}
df['two_mapping'] = df['two'].map(mapping)
df['two_mapping'] = df['two'].map(mapping2)
#mapping2의 저장되어있는 딕셔너리에는 70의 키값을 뺐는데 따로 매핑을 안해준 값은 NaN이라는 값이 나옴
#정확한 의미 -> # mapping2 딕셔너리에는 70에 해당하는 키가 없어서, df['two']에 70이 들어 있는 경우 NaN으로 매핑된다.


#value_counts() : 열의 고유한 값의 빈도수 계산
print(df['two'].value_counts())
print(df['two_mapping'].value_counts())
#Name: count, dtype: int64
#위 컬럼의 값들이 정리 되어 나왔는데 같은 값들은 묶어서 갯수를 세어준다,
#그리고 빈도수 아래에 Name가 dtype라고 따로 나와있는데
#이름은  시리즈의 이름을 말하는데 value_counts()로 호출한 시리즈의 이름은 count로 지정되서 나옴


#cut() : 연속형 데이터를 구간으 나눌때 사용
#cut(시리즈의이름 , bins, labels) 
#bins: 구간
#bins에서 0은 구간에 포함 되지 않는다
bins = [0, 30, 200, 500, 1000]
labels = ['낮음', '중간', '높음', '아주높음']
bins2 = [0, 30, 50, 60 ,70]
labels2 = ['낮음', '중간', '높음', '아주높음']
df['three_cut'] = pd.cut(df['three'], bins=bins, labels=labels)
df['three_cut'] = pd.cut(df['three'], bins=bins2, labels=labels2)
#해당 된 구간이 설젇되지 않는다면  NaN값 발생
df['two_cut'] = pd.cut(df['two'], bins=bins2, labels=labels2)

#2.그뤂화 집계
#agroupby(), agg()
#그룹화된 데이터에 집계 함수를 적용
#two_mapping값의 열을 기준으로 one열의 값의 평균을 구해준다
#-> 주석 수정
# 'two_mapping' 컬럼을 기준으로 그룹을 나눈 뒤,
# 각 그룹에 대해 'one' 컬럼의 평균(mean)을 계산한다
grouped = df.groupby('two_mapping')['one'].agg('mean')
print(grouped, type(grouped))
#아래에 데이터 타입은 one의 컬럼 즉 시리즈의 타입만 확인 했기 때문에 시리즈로 출력

#위에 처럼 해당 컬럼을 지정해주고 그룹화를 시켜주는것이 하나의 
#컬럼이 아닌 두 개 이상의 컬럼을 사용하고 싶을때 agg함수 인자에 딕셔너리 형태로 
#해준후 key값엔 컬럼명, 값에는 집계명을 적용해준다
grouped = df.groupby('two_mapping').agg({'one': 'mean', 'three' : 'sum'})
print(grouped, type(grouped))

#pivot_table
#b_#mapping 열 -> 인덱스, a_plus 열 -> 값으로 피벗테이블 생성
#위에서 했던 groupby와의 차이점은 기본은 1차원 Series / DataFrame	무조건 표(table) 형태
pivot_result = df.pivot_table(index='two_mapping', values='one_plus', aggfunc='mean')
print(pivot_result)
pivot_result = df.pivot_table(index='two_mapping', values='one_plus', aggfunc='min')
print(pivot_result)





```
